\section{From the two topics selected in Assignment 2, choose one topic as your primary research topic. This topic will form the basis for the remaining assignment, presentation, and project. Provide a detailed description of the problem domain, the data to be visualized, and the characteristics of the target users.}

The topic I choose is ``information retrieval on the web'', thus concentrating on web based search engines.

Web search engines are used for retrieving information from the web. They expect a \emph{query string} that consists of a number of \emph{search terms}. Each term is a single word or a fragment of a sentence enclosed in quotes. \emph{Search terms} can be ambiguous. ``Java'' for example is both an island and a programming language. ``Jobs'' might represent vocations or the current CEO of Apple Industries. A search engine processes the \emph{query string} by comparing its \emph{search terms} with a set of available documents. For web searches, this set will be all web pages accessible by the search engine. The search engine compares the content of the documents with the different \emph{search terms}, trying to find out the applicability of the individual documents. The results are typically returned as an ordered list. This order is the main benefit of a classic search engine, since it is the only semantic information generated. The idea is that the relative position of a a document in the list corresponds to the chance that this paper contains what the user is looking for. The position of a document is also called its ``ranking''.

The exact algorithm used for calculating the ranking of a document is kept secret by the search engine providers. It is however known that it is derived from multiple sources: The frequency that a \emph{search term} occurs inside a document displays how relevant the document might be in regard to that term. If multiple \emph{search terms} are used, the document with the highest combined frequency is likely to be the one most relevant to the full search query. Furthermore, web documents are connected to one another using \emph{links}. Most current search engines utilize these links in order to deduct the quality of a document. The more links target it, the more people suggest it, the better the quality. The quality is taken into consideration when the ranking of a document is evaluated.

Documents with a high ranking will be the first documents to be displayed, while documents with a low ranking will typically not even be visited by users. Because of that, web pages commonly court for better rankings. In order to achieve this, many pages try to falsely increase the numbers of links targeting itself and the number of occurrences of certain common \emph{search terms}. This causes a considerable loss of search quality, reduces the effectiveness of a search and makes it harder for the user to actually find what he is looking for.

Web documents typically consist of both textual and graphical information. For search engines, only the textual information is relevant, since web development paradigms specifically require textual meta-data in addition to every graphic used. This is necessary to provide accessibility for people with disabilities. Current helper-software is not able to process these graphics. Screen-readers, for example, rely on additionally provided information. It can therefore be assumed, that critical content encoded in graphics is always redundantly provided as meta-data.

Links cannot only be used for identifying the quality of a document, but also for identifying how different documents are connected. By taking the links into account when constructing the search result, relationships can be extrapolated. These relationships often indicate a semantical similarity, thus allowing a categorization of the documents. Unfortunately, most current web search engines do not use this option efficiently. Also, some documents might actually be sub-documents of one another. For example, a web site might have several pages. The documents are not only related to one another, but are actually different elements of one single document. It might furthermore be, that the different sub-documents actually refer to the same document. This relationship is usually displayed by web browsers.

Web search engines are used by a broad variety of people, ranging from professionals to novice users. It is important to support both kind of users, both the ones with much experience in searching and browsing the web, and those who have no idea how search engines, the Internet, or maybe even computers themselves are operated. Professional users might require a more flexible and powerful search interface, providing multiple features in order to narrow down the search results in advance. Non-professionals, however, have to be able to understand and use the interface intuitively. Both users have a few things in common: searching for a document is not their main task. Reading and processing the document is. Therefore, the search process has to run as quick and smooth as possible. Consequently, users will not be willing to spend much time learning the interface or adapting to changes. Search engines must therefore be as intuitive as possible. Also, users can be expected to be impatient with search engine, not wanting to spend too much time on the search task. Therefore, search engines must operate efficiently with great performance. Performing complex calculations on runtime might compromise this performance.